{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJx2ND17Oc6C6mIq/mL4ll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongsa-nut/TU_CN408_GenAI_671/blob/main/Lecture_5_RAG_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CN 408 - Lecture 5: RAG Demo"
      ],
      "metadata": {
        "id": "lR6f0qCXKX0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up LLM"
      ],
      "metadata": {
        "id": "NO9W08JgLcSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's set up Google Vertex AI"
      ],
      "metadata": {
        "id": "PVAsJ0_iKiGh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhCcC-R4KHJK"
      },
      "outputs": [],
      "source": [
        "!pip install -U google-cloud-aiplatform \"anthropic[vertex]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "id": "jfmtEdRHPxaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default set-quota-project gen-ai-demo-3 # replace the last one with your project ID"
      ],
      "metadata": {
        "id": "aiXXDqwGPxqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from anthropic import AnthropicVertex\n",
        "\n",
        "project_id = \"gen-ai-demo-3\" # replace this with your project ID\n",
        "region = \"us-east5\"  # Two region for Sonnet 3.5 [\"us-east5\", \"europe-west1\"]\n",
        "\n",
        "client = AnthropicVertex(project_id=project_id, region=region)\n",
        "\n",
        "# A simple Q&A generate code\n",
        "def generate(prompt):\n",
        "  response = client.messages.create(\n",
        "    model=\"claude-3-haiku@20240307\",\n",
        "    max_tokens=1000,\n",
        "    messages=[ { \"role\": \"user\", \"content\": prompt}]\n",
        "  )\n",
        "  return response.content[0].text\n",
        "\n",
        "generate(\"Hello test test\")"
      ],
      "metadata": {
        "id": "l2H_Q55gP05e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 1: Keyword Matching"
      ],
      "metadata": {
        "id": "RCHIjOUTLfUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data\n",
        "lorebook = { 'ตึกวิจัย' : 'ตำแหน่ง latitude = 14.0694899, longitude = 100.6050282',\n",
        "             'ตึกอำนวยการ' : 'ตำแหน่ง latitude = 14.0690024, longitude = 100.6061611'\n",
        "}"
      ],
      "metadata": {
        "id": "KR6PDnuTLqPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_generate(query, docs):\n",
        "  # Retrive information and create context\n",
        "  context = '<context>'\n",
        "  for k in docs:\n",
        "    if k in query:\n",
        "      context += f'{k} = {docs[k]}\\n'\n",
        "  context += '</context>'\n",
        "\n",
        "  prompt = f'''<question>{query}</question>\n",
        "  Please use context in <context> tags to answer the question.\n",
        "  <context>{context}</context>'''\n",
        "  response = generate(prompt)\n",
        "  # printing out\n",
        "  print('Query:', query)\n",
        "  print('Retrieved documents:', context)\n",
        "  print('Response:', response)\n",
        "\n",
        "query = 'ตึกวิจัยอยู่ไหน?'\n",
        "\n",
        "keyword_generate(query, lorebook)"
      ],
      "metadata": {
        "id": "Oh9tZBohNMy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 2: BM25"
      ],
      "metadata": {
        "id": "d4YUIn8vQUsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeGE2QcJc5P9",
        "outputId": "871793bc-7cca-436f-8d89-f093081f1d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.26.4)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi"
      ],
      "metadata": {
        "id": "bLLcL3dGQXO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample document collection\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"All that glitters is not gold.\",\n",
        "    \"Where there's smoke, there's fire.\",\n",
        "    \"The early bird catches the worm.\",\n",
        "    \"Actions speak louder than words.\",\n",
        "    \"Knowledge is power, but enthusiasm pulls the switch.\",\n",
        "    \"The pen is mightier than the sword.\",\n",
        "    \"When life gives you lemons, make lemonade.\"\n",
        "]\n",
        "\n",
        "# Simple tokenization using string splitting\n",
        "tokenized_docs = [doc.lower().split() for doc in documents]\n",
        "\n",
        "# Create BM25 object\n",
        "bm25 = BM25Okapi(tokenized_docs)"
      ],
      "metadata": {
        "id": "4yfWslkwdZ-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, top_k=2):\n",
        "  # Words only\n",
        "  tokenized_query = query.lower().split()\n",
        "  # Pass the list of words into bm25 to get scores\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "  # Then retrieve the score\n",
        "  top_docs = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)[:top_k]\n",
        "\n",
        "  return [documents[i] for i, _ in top_docs]"
      ],
      "metadata": {
        "id": "QRjJv2O5dvwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bm25_response(query):\n",
        "  retrieved_docs = retrieve(query)\n",
        "  context = \"\\n\".join(retrieved_docs)\n",
        "\n",
        "  prompt = f'''<question>{query}</question>\n",
        "  Please use context in <context> tags to answr the question.\n",
        "  <context>{context}</context>'''\n",
        "  response = generate(prompt)\n",
        "  # printing out\n",
        "  print('Query:', query)\n",
        "  print('Retrieved documents:', retrieved_docs)\n",
        "  print('Response:', response)\n",
        "\n",
        "query = \"What jumps over the dog?\"\n",
        "bm25_response(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jclDtDltd2aX",
        "outputId": "00a7dd75-a864-458f-9043-9b015b831fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What jumps over the dog?\n",
            "Retrieved documents: ['The quick brown fox jumps over the lazy dog.', 'A journey of a thousand miles begins with a single step.']\n",
            "Response: <context>The quick brown fox jumps over the lazy dog.</context>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 3: RAG without actual database"
      ],
      "metadata": {
        "id": "9OKu_c9XQXg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers datasets"
      ],
      "metadata": {
        "id": "WBgAHs-G2rxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "EeZPGTOglxCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same document collection\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"All that glitters is not gold.\",\n",
        "    \"Where there's smoke, there's fire.\",\n",
        "    \"The early bird catches the worm.\",\n",
        "    \"Actions speak louder than words.\",\n",
        "    \"Knowledge is power, but enthusiasm pulls the switch.\",\n",
        "    \"The pen is mightier than the sword.\",\n",
        "    \"When life gives you lemons, make lemonade.\"\n",
        "]\n",
        "\n",
        "# Initialize sentence transformer model\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Embed documents\n",
        "doc_embeddings = embed_model.encode(documents)"
      ],
      "metadata": {
        "id": "cdMfAmJiQb_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embeddings"
      ],
      "metadata": {
        "id": "7dteCYnrD54u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc_embeddings[0])"
      ],
      "metadata": {
        "id": "dcsDYhKnD-0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_RAG_docs(query, top_k=1):\n",
        "    # Embed the query\n",
        "    query_embedding = embed_model.encode([query])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
        "\n",
        "    # Get top-k relevant documents\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    return [documents[i] for i in top_indices]"
      ],
      "metadata": {
        "id": "gJeYSxVXl4p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RAG_response(query, top_k=3):\n",
        "  retrieved_docs = retrieve_RAG_docs(query, top_k)\n",
        "  context = \"\\n\".join(retrieved_docs)\n",
        "\n",
        "  prompt = f'''<question>{query}</question>\n",
        "  Please use context in <context> tags to answr the question.\n",
        "  <context>{context}</context>'''\n",
        "  response = generate(prompt)\n",
        "  # printing out\n",
        "  print('Query:', query)\n",
        "  print('Retrieved documents:', retrieved_docs)\n",
        "  print('Response:', response)\n",
        "\n",
        "query = \"What jumps over the dog?\"\n",
        "RAG_response(query)"
      ],
      "metadata": {
        "id": "PMjsoZmGl-4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 4: RAG with Pinecone"
      ],
      "metadata": {
        "id": "3xFmli7GHKNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pinecone"
      ],
      "metadata": {
        "id": "DcvarCOIHOri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec"
      ],
      "metadata": {
        "id": "O01aRLUcHPxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device != 'cuda':\n",
        "    print('Sorry no cuda.')\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
      ],
      "metadata": {
        "id": "7bN7jN1EHTFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What jumps over the dog?'\n",
        "xq = model.encode(query)\n",
        "xq.shape"
      ],
      "metadata": {
        "id": "IL2GZ9lbHWwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same document collection\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"All that glitters is not gold.\",\n",
        "    \"Where there's smoke, there's fire.\",\n",
        "    \"The early bird catches the worm.\",\n",
        "    \"Actions speak louder than words.\",\n",
        "    \"Knowledge is power, but enthusiasm pulls the switch.\",\n",
        "    \"The pen is mightier than the sword.\",\n",
        "    \"When life gives you lemons, make lemonade.\"\n",
        "]\n",
        "\n",
        "doc_embeddings = embed_model.encode(documents)"
      ],
      "metadata": {
        "id": "2wfKlSD-Hery"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Pinecone"
      ],
      "metadata": {
        "id": "ZzxE0W-KHaIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get secret key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "5u_ryrakNHC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=userdata.get('pinecone_key'))\n",
        "INDEX_NAME = 'test1-9-3-2024'\n",
        "\n",
        "# Cleaning up the index\n",
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "    pinecone.delete_index(INDEX_NAME)\n",
        "print(INDEX_NAME)\n",
        "\n",
        "# Creating a serverless index\n",
        "pinecone.create_index(\n",
        "    name = INDEX_NAME,\n",
        "    dimension = model.get_sentence_embedding_dimension(),\n",
        "    metric = 'cosine',\n",
        "    spec = ServerlessSpec(cloud='aws', region='us-east-1')) #\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)\n",
        "print(index)"
      ],
      "metadata": {
        "id": "WnujxL-7HaIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upsert to Pinecone\n",
        "\n",
        "- Format: A list of dict\n",
        "  - `{'id':xx, 'value':embedding, 'metadata':dict}`\n",
        "- Document: https://docs.pinecone.io/reference/api/2024-07/data-plane/upsert"
      ],
      "metadata": {
        "id": "G7q4_ScGHpq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create id\n",
        "ids = [str(x) for x in range(len(documents))]\n",
        "# Create metadata\n",
        "metadatas = [{'text': text} for text in documents]\n",
        "# Zip them together\n",
        "records = zip(ids, doc_embeddings, metadatas)\n",
        "index.upsert(vectors=records)   # There is a limit on how much you can upsert at a time. See https://docs.pinecone.io/guides/data/upsert-data"
      ],
      "metadata": {
        "id": "XdWVB_pYHsJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gkXZ3xrIHysW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriving Documents\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U2W1fv5UKhHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What jumps over the dog?'\n",
        "\n",
        "# 1) Embedding your query\n",
        "embed_query = model.encode(query).tolist()\n",
        "retrieved_docs =  index.query(vector=embed_query, top_k=1, include_metadata=True)\n",
        "print(retrieved_docs)"
      ],
      "metadata": {
        "id": "f9mGia8pKg1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [r['metadata']['text'] for r in retrieved_docs['matches']]\n",
        "print(text)"
      ],
      "metadata": {
        "id": "P5srP5e2L5q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate with retrived documents"
      ],
      "metadata": {
        "id": "wPdaAuH0KkDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RAG_pinecone_response(query, top_k=1):\n",
        "  # First embedding your query\n",
        "  embed_query = model.encode(query).tolist()\n",
        "  # Then retrieve the document\n",
        "  retrieved_docs =  index.query(vector=embed_query,\n",
        "                                top_k=top_k,\n",
        "                                include_metadata=True)\n",
        "  # Then get the actual text\n",
        "  text = [r['metadata']['text'] for r in retrieved_docs['matches']]\n",
        "  # Finally join them together\n",
        "  context = \"\\n\".join(text)\n",
        "\n",
        "  prompt = f'''<question>{query}</question>\n",
        "  Please use context in <context> tags to answr the question.\n",
        "  <context>{context}</context>'''\n",
        "  response = generate(prompt)\n",
        "  # printing out\n",
        "  print('Query:', query)\n",
        "  print('Retrieved documents:', text)\n",
        "  print('Response:', response)\n",
        "\n",
        "query = 'What jumps over the dog?'\n",
        "RAG_pinecone_response(query)"
      ],
      "metadata": {
        "id": "llnGF5A5Kd4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "### Demo 5: Search with Pinecone\n",
        "- Code snippet from https://learn.deeplearning.ai/courses/building-applications-vector-databases/lesson/1/introduction"
      ],
      "metadata": {
        "id": "BCvUUdKfQcS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pinecone"
      ],
      "metadata": {
        "id": "kuKUHP5L2aQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset   # From Huggingface. Need Hugging face token. Here: https://huggingface.co/docs/hub/en/security-tokens\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch"
      ],
      "metadata": {
        "id": "zAU3K2Eg2J9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('quora', split='train[240000:290000]')"
      ],
      "metadata": {
        "id": "jrml7Dc43fOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:5]"
      ],
      "metadata": {
        "id": "WqXlDdDO3Dtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "for record in dataset['questions']:\n",
        "    questions.extend(record['text'])\n",
        "question = list(set(questions))\n",
        "print('\\n'.join(questions[:10]))\n",
        "print('-' * 50)\n",
        "print(f'Number of questions: {len(questions)}')"
      ],
      "metadata": {
        "id": "eAanDNin3jQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Check cuda and Setup the model"
      ],
      "metadata": {
        "id": "o1dn48Gu3rlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device != 'cuda':\n",
        "    print('Sorry no cuda.')\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
      ],
      "metadata": {
        "id": "v3Rtpykn3rKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'which city is the most populated in the world?'\n",
        "xq = model.encode(query)\n",
        "xq.shape"
      ],
      "metadata": {
        "id": "9HxVO4In3ztc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Pinecone"
      ],
      "metadata": {
        "id": "_YftDeaa4DHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=userdata.get('pinecone_key'))\n",
        "INDEX_NAME = 'test1-9-3-2024'\n",
        "\n",
        "# Cleaning up the index\n",
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "    pinecone.delete_index(INDEX_NAME)\n",
        "print(INDEX_NAME)\n",
        "\n",
        "# Creating a serverless index\n",
        "pinecone.create_index(\n",
        "    name = INDEX_NAME,\n",
        "    dimension = model.get_sentence_embedding_dimension(),\n",
        "    metric = 'cosine',\n",
        "    spec = ServerlessSpec(cloud='aws', region='us-east-1')) #\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)\n",
        "print(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iJeuj-Q4FM_",
        "outputId": "6dcd576c-77f8-42e4-c8e2-3bd4f5c4ab7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test1-9-3-2024\n",
            "<pinecone.data.index.Index object at 0x7a0168a8f5e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embeddings and Upsert to Pinecone"
      ],
      "metadata": {
        "id": "t0Ub94kr4akg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=200\n",
        "vector_limit=10000\n",
        "\n",
        "questions = question[:vector_limit]\n",
        "\n",
        "\n",
        "for i in tqdm(range(0, len(questions), batch_size)):\n",
        "    # find end of batch\n",
        "    i_end = min(i+batch_size, len(questions))\n",
        "    # create IDs batch\n",
        "    ids = [str(x) for x in range(i, i_end)]\n",
        "    # create metadata batch\n",
        "    metadatas = [{'text': text} for text in questions[i:i_end]]\n",
        "    # create embeddings\n",
        "    xc = model.encode(questions[i:i_end])\n",
        "    # create records list for upsert\n",
        "    records = zip(ids, xc, metadatas)\n",
        "    # upsert to Pinecone\n",
        "    index.upsert(vectors=records)"
      ],
      "metadata": {
        "id": "n53UqH_p4djS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "akA45ZIV4hbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run your query"
      ],
      "metadata": {
        "id": "C6JraJWP4ian"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# small helper function so we can repeat queries later\n",
        "def run_query(query):\n",
        "  embedding = model.encode(query).tolist()\n",
        "  results = index.query(top_k=10,\n",
        "                        vector=embedding,\n",
        "                        include_metadata=True,\n",
        "                        include_values=False)\n",
        "  for result in results['matches']:\n",
        "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
      ],
      "metadata": {
        "id": "u65TLni44mDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'which city has the highest population in the world?'\n",
        "run_query(query)"
      ],
      "metadata": {
        "id": "h43-FMdo4nQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 6: RAG with images and text using Pinecone"
      ],
      "metadata": {
        "id": "CK3m_XETQgbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In this example, we will search with both images and text.\n",
        "- The idea is still the same. You embed images and texts and then upend to the database."
      ],
      "metadata": {
        "id": "z5rxIHYIQAPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Pinecone"
      ],
      "metadata": {
        "id": "yBau3BzFQZOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=userdata.get('pinecone_key'))\n",
        "INDEX_NAME = 'test1-9-3-2024'\n",
        "\n",
        "# Cleaning up the index\n",
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "    pinecone.delete_index(INDEX_NAME)\n",
        "print(INDEX_NAME)\n",
        "\n",
        "# Creating a serverless index\n",
        "pinecone.create_index(\n",
        "    name = INDEX_NAME,\n",
        "    dimension =512,\n",
        "    metric = 'dotproduct',\n",
        "    spec = ServerlessSpec(cloud='aws', region='us-east-1')) #\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)\n",
        "print(index)"
      ],
      "metadata": {
        "id": "V2EZcwJ2QkY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion = load_dataset(\n",
        "    \"ashraq/fashion-product-images-small\",\n",
        "    split=\"train\"\n",
        ")\n",
        "fashion"
      ],
      "metadata": {
        "id": "-3wEJRqoRLBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = fashion['image']\n",
        "metadata = fashion.remove_columns('image')\n",
        "images[900]"
      ],
      "metadata": {
        "id": "9ATAyB6LRM3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = metadata.to_pandas()\n",
        "metadata.head()"
      ],
      "metadata": {
        "id": "yk4WYY1AROFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Sparse Vector Using BM25"
      ],
      "metadata": {
        "id": "J8lTN4tkRQCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone_text"
      ],
      "metadata": {
        "id": "FGxN7BaWRbzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone_text.sparse import BM25Encoder\n",
        "\n",
        "bm25 = BM25Encoder()\n",
        "bm25.fit(metadata['productDisplayName'])\n",
        "metadata['productDisplayName'][0]"
      ],
      "metadata": {
        "id": "Gb5veEbcRTF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm25.encode_queries(metadata['productDisplayName'][0])\n",
        "bm25.encode_documents(metadata['productDisplayName'][0])"
      ],
      "metadata": {
        "id": "HCfML205RiEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Dense Vector Using CLIP"
      ],
      "metadata": {
        "id": "toBBd0BdRjXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('sentence-transformers/clip-ViT-B-32', device=device)\n",
        "model\n",
        "dense_vec = model.encode([metadata['productDisplayName'][0]])\n",
        "dense_vec.shape"
      ],
      "metadata": {
        "id": "fK_jApKCRlUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fashion)"
      ],
      "metadata": {
        "id": "ahplkFsdRmTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embeddings Using Sparse and Dense"
      ],
      "metadata": {
        "id": "EhqS9VIkRtWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "fashion_data_num = 1000\n",
        "\n",
        "for i in tqdm(range(0, min(fashion_data_num,len(fashion)), batch_size)):\n",
        "    # find end of batch\n",
        "    i_end = min(i+batch_size, len(fashion))\n",
        "    # extract metadata batch\n",
        "    meta_batch = metadata.iloc[i:i_end]\n",
        "    meta_dict = meta_batch.to_dict(orient=\"records\")\n",
        "    # concatinate all metadata field except for id and year to form a single string\n",
        "    meta_batch = [\" \".join(x) for x in meta_batch.loc[:, ~meta_batch.columns.isin(['id', 'year'])].values.tolist()]\n",
        "    # extract image batch\n",
        "    img_batch = images[i:i_end]\n",
        "    # create sparse BM25 vectors\n",
        "    sparse_embeds = bm25.encode_documents([text for text in meta_batch])\n",
        "    # create dense vectors\n",
        "    dense_embeds = model.encode(img_batch).tolist()\n",
        "    # create unique IDs\n",
        "    ids = [str(x) for x in range(i, i_end)]\n",
        "\n",
        "    upserts = []\n",
        "    # loop through the data and create dictionaries for uploading documents to pinecone index\n",
        "    for _id, sparse, dense, meta in zip(ids, sparse_embeds, dense_embeds, meta_dict):\n",
        "        upserts.append({\n",
        "            'id': _id,\n",
        "            'sparse_values': sparse,\n",
        "            'values': dense,\n",
        "            'metadata': meta\n",
        "        })\n",
        "    # upload the documents to the new hybrid index\n",
        "    index.upsert(upserts)\n",
        "\n",
        "# show index description after uploading the documents\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "CvnFlNRkR_Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Your Query"
      ],
      "metadata": {
        "id": "E6hEFuM_SCiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"dark blue french connection jeans for men\"\n",
        "\n",
        "sparse = bm25.encode_queries(query)\n",
        "dense = model.encode(query).tolist()\n",
        "\n",
        "result = index.query(\n",
        "    top_k=14,\n",
        "    vector=dense,\n",
        "    sparse_vector=sparse,\n",
        "    include_metadata=True\n",
        ")\n",
        "\n",
        "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
        "imgs"
      ],
      "metadata": {
        "id": "1uxDfXh7SDa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "from io import BytesIO\n",
        "from base64 import b64encode\n",
        "\n",
        "# function to display product images\n",
        "def display_result(image_batch):\n",
        "    figures = []\n",
        "    for img in image_batch:\n",
        "        b = BytesIO()\n",
        "        img.save(b, format='png')\n",
        "        figures.append(f'''\n",
        "            <figure style=\"margin: 5px !important;\">\n",
        "              <img src=\"data:image/png;base64,{b64encode(b.getvalue()).decode('utf-8')}\" style=\"width: 90px; height: 120px\" >\n",
        "            </figure>\n",
        "        ''')\n",
        "    return HTML(data=f'''\n",
        "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
        "        {''.join(figures)}\n",
        "        </div>\n",
        "    ''')"
      ],
      "metadata": {
        "id": "TGcw1M3bSFf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_result(imgs)"
      ],
      "metadata": {
        "id": "549dbmrDSGjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling the Hybrid Search"
      ],
      "metadata": {
        "id": "3oC6gmAwSII1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_scale(dense, sparse, alpha: float):\n",
        "    \"\"\"Hybrid vector scaling using a convex combination\n",
        "\n",
        "    alpha * dense + (1 - alpha) * sparse\n",
        "\n",
        "    Args:\n",
        "        dense: Array of floats representing\n",
        "        sparse: a dict of `indices` and `values`\n",
        "        alpha: float between 0 and 1 where 0 == sparse only\n",
        "               and 1 == dense only\n",
        "    \"\"\"\n",
        "    if alpha < 0 or alpha > 1:\n",
        "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
        "    # scale sparse and dense vectors to create hybrid search vecs\n",
        "    hsparse = {\n",
        "        'indices': sparse['indices'],\n",
        "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
        "    }\n",
        "    hdense = [v * alpha for v in dense]\n",
        "    return hdense, hsparse"
      ],
      "metadata": {
        "id": "ll68MNZ6STLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. More Dense"
      ],
      "metadata": {
        "id": "CjjmH0f5SU77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"dark blue french connection jeans for men\"\n",
        "#Closer to 0==more sparse, closer to 1==more dense\n",
        "hdense, hsparse = hybrid_scale(dense, sparse, alpha=1)\n",
        "result = index.query(\n",
        "    top_k=6,\n",
        "    vector=hdense,\n",
        "    sparse_vector=hsparse,\n",
        "    include_metadata=True\n",
        ")\n",
        "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
        "display_result(imgs)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oeCZJtW-SV1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in result[\"matches\"]:\n",
        "    print(x[\"metadata\"]['productDisplayName'])"
      ],
      "metadata": {
        "id": "vEJj-UgTSX6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. More Sparse"
      ],
      "metadata": {
        "id": "3R7cofgFSYOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"dark blue french connection jeans for men\"\n",
        "#Closer to 0==more sparse, closer to 1==more dense\n",
        "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0)\n",
        "result = index.query(\n",
        "    top_k=6,\n",
        "    vector=hdense,\n",
        "    sparse_vector=hsparse,\n",
        "    include_metadata=True\n",
        ")\n",
        "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
        "display_result(imgs)"
      ],
      "metadata": {
        "id": "iJYJPz3FSZzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in result[\"matches\"]:\n",
        "    print(x[\"metadata\"]['productDisplayName'])"
      ],
      "metadata": {
        "id": "HD-fAE3NSa7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More Dense or More Sparse?"
      ],
      "metadata": {
        "id": "NsXSZ6m7Se-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"dark blue french connection jeans for men\"\n",
        "#Closer to 0==more sparse, closer to 1==more dense\n",
        "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0.5)\n",
        "result = index.query(\n",
        "    top_k=6,\n",
        "    vector=hdense,\n",
        "    sparse_vector=hsparse,\n",
        "    include_metadata=True\n",
        ")\n",
        "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
        "display_result(imgs)\n"
      ],
      "metadata": {
        "id": "UPR-7hcJSfrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in result[\"matches\"]:\n",
        "    print(x[\"metadata\"]['productDisplayName'])"
      ],
      "metadata": {
        "id": "HEHg78BxShhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}